import asyncio
from langchain_mcp_adapters.client import MultiServerMCPClient
from typing import TypedDict, Annotated
from langgraph.graph.message import add_messages
from langchain_core.messages import AIMessage, ToolMessage, SystemMessage
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import ToolNode
import os


class State(TypedDict):
        messages: Annotated[list, add_messages]


async def get_tool_list(config_mcp_server):
        client = MultiServerMCPClient(config_mcp_server)
        tools_list = await client.get_tools()
        print("Tools fetched from MCP:", [tool.name for tool in tools_list])
        return tools_list
    
config_mcp_server = {
        "email_reader_mcp":{
            "url":"http://0.0.0.0:8655/api/v1/email_intent_agent/mcp",
            # "url":"http://jarvis-mcp-test4.b4egcthqf2a2hce2.eastus.azurecontainer.io:8655/api/v1/email_intent_agent/mcp",
            "transport":"streamable_http",
        }}


def router(state: State):
    last_message = state["messages"][-1]
    if isinstance(last_message, AIMessage) and getattr(last_message, 'tool_calls', None):
        return "tools"
    if isinstance(last_message, AIMessage) and last_message.content:
        content = last_message.content
        if ('Continue' in content) :
            return "tools"
        elif ("End" in content):
            return "End"
    return "End"

def load_prompt(path: str) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read()


def create_custom_graph(model, tools, prompt, checkpointer=None):
    #format_instruction, response_class = response_format
    graph_builder = StateGraph(State)

    llm_with_tools = model.bind_tools(tools)

    async def agent_node(state: State):
        messages = state["messages"]
        system_prompt = SystemMessage(content=prompt)
        all_messages = [system_prompt] + messages
        message = await llm_with_tools.ainvoke(all_messages)
        return {"messages": [message]}


    
    graph_builder.add_node("agent", agent_node)
    graph_builder.add_node("tools", ToolNode(tools=tools))
    

    graph_builder.add_edge(START, "agent")
    graph_builder.add_conditional_edges(
        "agent", 
        router, 
        {
            "tools": "tools",
            "End": END
        })
    graph_builder.add_edge("tools", "agent")
    

    return graph_builder.compile(checkpointer=checkpointer) if checkpointer else graph_builder.compile()

async def main():
#async def email_intent_agent():
    tools = await get_tool_list(config_mcp_server=config_mcp_server)
    

    
    from dotenv import load_dotenv
    load_dotenv()

    from langchain_openai.chat_models import AzureChatOpenAI

    endpoint = os.environ["AZURE_INFERENCE_ENDPOINT"] = os.getenv("AZURE_OPENAI_ENDPOINT")
    credential = os.environ["AZURE_INFERENCE_CREDENTIAL"] = os.getenv("AZURE_OPENAI_API_KEY")
    model = os.environ["AZURE_OPENAI_CHAT_DEPLOYMENT_NAME"] = os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT")

    model = AzureChatOpenAI(
        api_key="some key",
        api_version="2025-01-01-preview",
        azure_deployment="gpt-4.1-jarvis",
        azure_endpoint="https://agenticinsuranceopenai.openai.azure.com/"
    )

    

    llm_with_tools = model.bind_tools(tools)

    SYSTEM_INSTRUCTION = load_prompt("./prompt4.txt")

    graph = create_custom_graph(model=model, tools=tools, prompt=SYSTEM_INSTRUCTION)

    
    last_message = None
    async for chunk in graph.astream({"messages": ["Start your task"]},
                                    config={"recursion_limit": 100}):

        # If the agent responded
        if "agent" in chunk:
            messages = chunk["agent"]["messages"]
            for msg in messages:
                if isinstance(msg, AIMessage):
                    # Print tool calls if present
                    if getattr(msg, "tool_calls", None):
                        print("[Agent] (tool call issued)\n")
                        for call in msg.tool_calls:
                            print(f"   → Tool name: {call['name']}")
                            print(f"   → Arguments: {call['args']}\n***********************************************")
                    # Otherwise print normal content
                    elif msg.content:
                        print(f"[Agent] {msg.content}\n***********************************************")
                    else:
                        print("[Agent] (empty)\n***********************************************")
                else:
                    print(f"[Agent] {msg}\n***********************************************")

        # If a tool responded
        if "tools" in chunk:
            messages = chunk["tools"]["messages"]
            for msg in messages:
                if isinstance(msg, ToolMessage):
                    print(f"[Tool:{msg.name}] {msg.content}\n***********************************************")
                else:
                    print(f"[Tool] {msg}\n***********************************************")



if __name__ == "__main__":
    asyncio.run(main())

above is a file named orchestrator.py,

then there is also main.py 
from fastapi import FastAPI

from fastapi.middleware.cors import CORSMiddleware

from fastapi_mcp import FastApiMCP

import uvicorn 
 
from test_email_router import router as email_router

from email_reader_mcp.email_handler import get_latest_email, start_email_polling, stop_email_polling

from contextlib import asynccontextmanager

# from data_extractor_mcp.image_processor import process_input_folder_on_startup

import asyncio

from email_output_saver_mcp.email_output_saver import start_output_saver_polling, stop_output_saver_polling

#custom_model_dataextractor
from custom_model_dataextractor_mcp.image_processor import process_input_folder_on_startup

# risk type checker mcp


# Risk score Calculator MCP 
from risk_score_calculator_mcp.risk_calculator import RuleBasedRiskCalculator 

#accept/reject_risk_functionality_mcp
from accept_reject_risk_functionality_mcp import agent_core
from accept_reject_risk_functionality_mcp.agent_core import process_risk_from_blob, RiskThresholds


async def _start_processing_task() -> None:
    """
    Create and store a background task that runs the processor.
    This returns immediately after scheduling the task.
    """
    # schedule background processing
    task = asyncio.create_task(process_input_folder_on_startup())
    # stash on the running app (will be attached in lifespan)
    return task

async def _stop_processing_task(task: asyncio.Task) -> None:
    """
    Cancel and await the background task if it's still running.
    """
    if task and not task.done():
        task.cancel()
        try:
            await task
        except Exception:
            # swallow exceptions on shutdown
            pass


# @asynccontextmanager
# async def lifespan(app: FastAPI):
#     # Startup
#     await start_email_polling()
#     yield
#     # Shutdown
#     await stop_email_polling()
#     # Startup: schedule the processing task and attach to app.state
#     try:
#         app.state.processing_task = await _start_processing_task()
#     except Exception:
#         app.state.processing_task = None

#     yield

#     # Shutdown: cancel the task if running
#     task = getattr(app.state, "processing_task", None)
#     if task:
#         await _stop_processing_task(task)

#     # Startup: perform a single upload pass
#     await start_output_saver_polling()
#     yield
#     # Shutdown: no-op
#     await stop_output_saver_polling()


app = FastAPI()

# app = FastAPI(lifespan=lifespan)

def apply_cors(app: FastAPI):
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_methods=["*"],
        allow_headers=["*"],
    )

def create_sub_app(title: str, description: str, version: str = "0.1.0") -> FastAPI:
    app = FastAPI(title=title, description=description, version=version)
    #app = FastAPI(title=title, description=description, version=version, lifespan=lifespan)
    apply_cors(app)
    return app

apply_cors(app)

email_intent_agent_app = create_sub_app(title="email_intent_agent_mcps", description="role is to handle the initial stage of the underwriting workflow — focused solely on understanding the incoming emails")
email_intent_agent_app.include_router(email_router)
FastApiMCP(email_intent_agent_app, include_operations=["email_reader_mcp","attachment_checker_mcp","email_attachment_mcp","layout_detection_mcp","document_extract_mcp","excel_loader_mcp", "pdf_vectorizer_mcp", "retriever_mcp","email_processed_mcp","risk_type_checker_MCP","renewal_checker_mcp","Licensing_and_Sanction_Checker_MCP","risk_data_capture_mcp","risk_score_calculator_mcp","Json_Reader_Read","accept_reject_risk_functionality_mcp","attachment_summary_mcp","query_pdf_vectorizer_mcp", "query_retriever_mcp","write_email_to_excel"]).mount_http()
#app.mount("/mcp",email_reader_app)
app.mount("/api/v1/email_intent_agent",email_intent_agent_app)

if __name__=="__main__":
    uvicorn.run(app, host="0.0.0.0", port=8655)

also router.py
import os 
from dotenv import load_dotenv
load_dotenv()
from fastapi import Body
from fastapi import APIRouter
import asyncio
from email_reader_mcp.email_handler import get_latest_email, start_email_polling, stop_email_polling
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from typing import Optional

from contextlib import asynccontextmanager


#custom_model_dataextractor_mcp
from custom_model_dataextractor_mcp.image_processor import analyze_file_async

from pydantic import BaseModel, Field, validator
 

router = APIRouter()


#duplicate_checker_mcp specific imports

from duplicate_attachment_checker_mcp.attachment_service import get_latest_email_attachment_check

#attachment_downloader_mcp specific imports

from attachment_downloader_mcp.attachment_handler import get_latest_email_attachment_downloader, start_email_polling, stop_email_polling

#data_extractor_mcp specific
# from data_extractor_mcp.image_processor import analyze_file_async

#document_layout_classification
from document_layout_classification.handler import classify_blob_pdf_layout

#Quote_extraction_mcp
from Quote_Extraction_MCP.excel_loader import process_upload
from Quote_Extraction_MCP.pdf_to_vector import process_pdf
from Quote_Extraction_MCP.retriever import process_retrieval
from typing import List

#email_output_saver_mcp
from email_output_saver_mcp.email_output_saver import process_upload_all_json

#risk_type_checker_mcp
from risk_type_checker_mcp.lob_handler import identify_lob_for_risk_type

#renewal_newbusiness_checker_mcp
from renewal_newbusiness_checker_mcp.checker import run_once, run_once_json
from renewal_newbusiness_checker_mcp.service import _parse_blob_url
from pydantic import BaseModel, Field, model_validator
from typing import Optional, Any, Dict
#licensing_sanction_checker_mcp

from licensing_sanction_checker_mcp.handler import compare_name_with_sanctions
#accept_reject_risk_functionallity_mcp
from accept_reject_risk_functionality_mcp.agent_core import RiskThresholds, process_risk_from_blob

# risk score calculator mcp 
from risk_score_calculator_mcp.risk_calculator import RuleBasedRiskCalculator
calculator = RuleBasedRiskCalculator()



#json_reader_mcp
from json_reader_mcp.reader_handler import retrieve_full_json

# risk data capture mcp
from risk_data_capture_mcp.handler import capture_risk_data


#attachment_summary_mcp
from attachment_summary_mcp.summary_handler import summarize_blob_pdfs_layout  
from typing import List

# document_query_mcp
from fastapi import UploadFile, File, Form
import json
from Document_Query_MCP.query_pdf_to_vector import process_query_pdf
from Document_Query_MCP.query_retriever import process_query_retrieval

# email_writer_mcp
from email_writer_mcp.writer import write_email_data_to_excel

class EmailReaderMCP(BaseModel):
    """Represents the functionality of reading emails from the inbox of Underwriter"""
    AgentName: str = Field(default="EmailIntentAgent", description=("The unique agent name of the agent that is being called"))
    UserId: str = Field(default="markRuffalo", description=("The unique user id of a specific user (default: 'markRuffalo')."))


@router.post("/email_reader_mcp", operation_id="email_reader_mcp")
#async def email_reader_mcp(p_body: EmailReaderMCP = Body()):
async def email_reader_mcp():
    """Reads the email from inbox of Underwriter and return the email body
    Args:

        p_body (EmailReaderMCP): Request body containing:

            AgentName (str): The unique agent name of the agent that is being called.

            UserId (str): The unique user id of a specific user (default: 'markRuffalo').
 
    """
    try:
        result = get_latest_email()
    except Exception as e:
        return {"error": f"Unable to get the latest email: {e}"}

    return JSONResponse(content={
        "jsonrpc": "2.0",
        "id": 1,
        "result": result
    })


class AttachmentCheckerMCP(BaseModel):
    
    """Represents the functionality of checking email attachments for duplicate in Azure Blob."""

    AgentName: str = Field(default="EmailAttachmentChecker", description="Agent name.")
    UserId: str = Field(default="markRuffalo", description="User id (default).")
@router.post("/attachment_checker_mcp", operation_id="attachment_checker_mcp")
# async def attachment_checker_mcp(p_body: AttachmentCheckerMCP):
async def attachment_checker_mcp():

    """
    Fetches the latest Gmail email and checks if its attachments already exist in Azure Blob Storage.
    Args:
        p_body (AttachmentCheckerMCP): Request body containing:
            AgentName (str): The name of the MCP agent calling this endpoint.
            UserId (str): Identifier for the user making the request.
    Returns:
        JSONResponse: Returns JSON-RPC response containing:
            status (bool): True if executed successfully, else False.
            attachments (list): List of attachment comparison results.
            error (str, optional): Error message if any exception occurred.
    """

    try:
        result = get_latest_email_attachment_check()
        if result.get("status") is True and "attachments" not in result:
            result["attachments"] = []
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "result": result
            }
        )
    except Exception as e:
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "result": {"status": False, "error": str(e)}
            },
            status_code=200
        )


class EmailAttachmentMCP(BaseModel):
    """Represents the functionality of reading emails from the inbox of Underwriter"""
    AgentName: str = Field(default="EmailIntentAgent", description="The unique agent name of the agent that is being called")
    UserId: str = Field(default="markRuffalo", description="The unique user id of a specific user (default: 'markRuffalo').")
    ref_id: str = Field(..., description="This reference id will be provided as a part of json output of email_reader_mcp")

@router.post("/email_attachment_mcp", operation_id="email_attachment_mcp")
async def email_attachment_mcp(p_body: EmailAttachmentMCP = Body()):
    """Reads the email from inbox of Underwriter and returns the email attachments if any."""
    try:
        result = get_latest_email_attachment_downloader(ref_id=p_body.ref_id)
    except Exception as e:
        return {"error": f"Unable to get the latest email: {e}"}

    return JSONResponse(content={
        "jsonrpc": "2.0",
        "id": 1,
        "result": result
    })




# class DocumentExtractMCP(BaseModel):
#     """Trigger document extraction for a PDF file located in the input folder (now blob storage)."""
#     AgentName: str = Field(
#         default="DocumentExtractAgent",
#         description="The unique agent name of the agent that is being called"
#     )
#     Filename: Optional[str] = Field(
#         default="https://{agenticai1}.blob.core.windows.net/{attachment-downloader}/{filename}",
#         description="Optional filename (PDF) in blob container to analyze"
#     )
    

# @router.post("/document_extract_mcp", operation_id="document_extract_mcp")
# async def document_extract_mcp(p_body: DocumentExtractMCP):
#     """
#     Analyze a PDF from the Azure Blob container using image_processor.analyze_file_async and
#     return the analyzer's structured result.

#     Body:

#         AgentName (str): Agent name (optional)

#         Filename (str): Optional PDF filename in blob container; if omitted, the most recent PDF is used.
#     """
#     try:
#         # Single try block: delegate all work to image_processor
#         result = await analyze_file_async(p_body.Filename)

#         return JSONResponse(content={
#             "jsonrpc": "2.0",
#             "id": 1,
#             "result": result
#         })

#     except Exception as e:
#         return {"error": f"Extraction failed: {e}"}




#custom_model_dataextractor_mcp
#custom_model_dataextractor_mcp
class DocumentExtractMCP(BaseModel):
    """Trigger document extraction for a PDF file located in blob storage."""
    AgentName: str = Field(
        default="DocumentExtractAgent",
        description="The unique agent name of the agent that is being called"
    )
    BlobUrl: str = Field(
        ...,
        description="Required: full blob URL (https://...) or container/blob path (container/path/to/file.pdf) to analyze"
    )

    @validator("BlobUrl")
    def bloburl_must_not_be_empty(cls, v: str) -> str:
        if not v or not v.strip():
            raise ValueError("BlobUrl must be a non-empty string pointing to the blob (full URL or container/blob path).")
        return v.strip()


@router.post("/document_extract_mcp", operation_id="document_extract_mcp")
async def document_extract_mcp(p_body: DocumentExtractMCP):
    """
    Analyze a PDF from Azure Blob storage using image_processor.analyze_file_async and
    return the analyzer's structured result.

    Body:

        AgentName (str): Agent name (optional)

        BlobUrl (str): Required full blob URL or container/blob path.
    """
    try:
        result = await analyze_file_async(bloburl=p_body.BlobUrl)

        return JSONResponse(content={
            "jsonrpc": "2.0",
            "id": 1,
            "result": result
        })

    except Exception as e:
        return JSONResponse(status_code=500, content={"error": f"Extraction failed: {e}"})


#document_layout_classification


class LayoutDetectRequest(BaseModel):
    """
    Payload:
    {
      "attachment_url": "https://<account>.blob.core.windows.net/<container>/<path>/file.pdf"
    }
    """
    attachment_url: str = Field(..., description="Full Azure Blob URL of the PDF attachments returned by the 'email_attachment_mcp' having either 'ACORD' or 'Quote' keyword in the file name.")

@router.post("/layout_detection_mcp", operation_id="layout_detection_mcp",
             summary="Download PDF from blob, analyze layout using Form Recognizer, and classify layout")
async def detect_layout(request: LayoutDetectRequest):
    """Analyze the document to classify if the document is ACORD or Quote
    
    Args:
        attachment_url: The Blob URL oreturned by the email_attachment_mcp
    
    Returns:
        JSONResponse: returns the json response containing the classification of the layout.
    """
    try:
        result = await classify_blob_pdf_layout(request.attachment_url)
        return JSONResponse(content={"jsonrpc": "2.0", "id": 1, "result": result}, status_code=200)
    except Exception as e:
        return JSONResponse(content={"jsonrpc": "2.0", "id": 1,
                                     "result": {"status": False, "error": str(e)}}, status_code=200)



# Quote extraction mcp 3 routers are as below

@router.post("/excel_loader_mcp", operation_id="excel_loader_mcp")
async def excel_loader_mcp():
    """Loads Excel file and extracts attributes

        
    
    Returns:
        JSONResponse: Contains the extracted attributes in list format and metadata
    """
    try: 
        # Delegate the full business logic to the excel_loader module
        excel_file = os.getenv("EXCEL_FILE_PATH")
        result = await process_upload(excel_file)

        return JSONResponse(content={
            "jsonrpc": "2.0",
            "id": 1,
            "result": result,
        })
        
    except Exception as e:
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "error": {
                    "code": 500,
                    "message": f"Error processing Excel file: {str(e)}"
                }
            },
            status_code=500
        )

class PdfVectorizerMCP(BaseModel):
    """Represents the functionality of vectorizing PDFs and storing them in vector DB"""
    AgentName: str = Field(default="PdfVectorizerAgent", description="The unique agent name of the agent that is being called")
    UserId: str = Field(default="markRuffalo", description="The unique user id of a specific user")
    BlobUrl: str = Field(..., description="Full blob URL (http(s)://) to the PDF file")

class RetrieverMCP(BaseModel):
    """Represents the functionality of retrieving values for attributes from vectorized PDFs"""
    # AgentName: str = Field(default="RetrieverAgent", description="The unique agent name of the agent that is being called")
    # UserId: str = Field(default="markRuffalo", description="The unique user id of a specific user")
    VectorDbPath: str = Field(..., description="Path to the vector database")
    Attributes: List[str] = Field(..., description="List of attributes which are of string type extracted from the PDF")
    Instructions: List[str] = Field(default_factory=list, description="List of instructions corresponding to each attribute")

@router.post("/pdf_vectorizer_mcp", operation_id="pdf_vectorizer_mcp")
async def pdf_vectorizer_mcp(
    p_body: PdfVectorizerMCP,
):
    """Vectorize a PDF from blob storage and save embeddings to Chroma vector DB.
    
    Args:
        p_body (PdfVectorizerMCP): Request body containing blob URL
    
    Returns:
        JSONResponse: Contains vectorization status and metadata
    """
    try:
        result = await process_pdf(blob_url=p_body.BlobUrl)
        
        return JSONResponse(content={
            "jsonrpc": "2.0",
            "id": 1,
            "result": result
        })
        
    except Exception as e:
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "error": {
                    "code": 500,
                    "message": f"Error vectorizing PDF: {str(e)}"
                }
            },
            status_code=500
        )

@router.post("/retriever_mcp", operation_id="retriever_mcp")
async def retriever_mcp(
    p_body: RetrieverMCP,
):
    """Retrieve the context for given query which is in the form of attribute listfrom vector db using semantic search.
    
    Args:
    VectorDbPath: str = Field(..., description="Path to the vector database returned by pdf_vectorizer_mcp")
    Attributes: List[str] = Field(..., description="List of attributes to extract from the PDF returned by excel_loader_mcp")
    Instructions: List[str] = Field(default_factory=list, description="List of instructions corresponding to each attribute")
    Returns:
        JSONResponse: Contains extraction results and output blob URL
    """
    try:
        result = await process_retrieval(
            vector_db_path=p_body.VectorDbPath,
            attributes=p_body.Attributes,
            instructions=p_body.Instructions
        )
        
        return JSONResponse(content={
            "jsonrpc": "2.0",
            "id": 1,
            "result": result
        })
        
    except Exception as e:
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "error": {
                    "code": 500,
                    "message": f"Error retrieving values: {str(e)}"
                }
            },
            status_code=500
        )







class EmailProcessedMCP(BaseModel):
    """Represents saving processed email outputs into Azure Blob Storage."""
    AgentName: str = Field(default="EmailProcessedAgent", description="Unique agent name being called.")
    UserId: str = Field(default="markRuffalo", description="Unique user id (default: 'markRuffalo').")

@router.post("/email_processed_mcp", operation_id="email_processed_mcp")
async def email_processed_mcp(p_body: EmailProcessedMCP = Body()):
    """
    Uploads all local .json files from the configured input directory to Azure Blob Storage.
    If a blob already exists, it is skipped to avoid duplicates.
    """
    try:
        result = process_upload_all_json()
    except Exception as e:
        return {"error": f"Unable to upload JSON files: {e}"}

    return JSONResponse(content={
        "jsonrpc": "2.0",
        "id": 1,
        "result": result
    })


class RiskTypeCheckerRequest(BaseModel):
    """Represents the functionality for detecting the most relevant Line of Business from structured business data."""
    AgentName: str = Field(default="EligibilityAgent", description=("The unique agent name of the agent that is being called"))
    UserId: str = Field(default="markRuffalo", description=("The unique user id of a specific user (default: 'markRuffalo')."))
    file_path: str = Field(..., description="Full blob URL to the JSON file in Azure Blob Storage.")

@router.post("/risk_type_checker", operation_id="risk_type_checker_MCP")
async def detect_lob_for_risk_type(p_body: RiskTypeCheckerRequest):
    """
    Detects the most relevant Line of Business from structured business data.

    Args:
        p_body (RiskTypeCheckerRequest): Request body containing:
        AgentName (str): The unique agent name of the agent that is being called.
        UserId (str): The unique user id of a specific user (default: 'markRuffalo').
        file_path (str): Full blob URL to the JSON file in Azure Blob Storage.
    """
    try:
        result = identify_lob_for_risk_type(p_body.file_path)
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "result": result
            },
            status_code=200
        )
    except Exception as e:
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "result" : result
            },
            status_code=200
        )


class RenewalCheckerMCP(BaseModel):
    """Represents the Renewal/New Business Checker MCP."""
    AgentName: str = Field(default="RenewalNewBusinessChecker", description="Agent name.")
    BlobUrl: Optional[str] = Field(default=None, description="Full blob URL to analyze.")
    RawJson: Optional[Dict[str, Any]] = Field(default=None, description="Optional inline extracted JSON for testing.")

    @model_validator(mode="after")
    def validate_blob_or_json(self):
        blob = self.BlobUrl
        raw = self.RawJson
        if (not blob or not str(blob).strip()) and not raw:
            raise ValueError("Either BlobUrl (non-empty) or RawJson (object) must be provided.")
        return self


@router.post("/renewal_checker_mcp", operation_id="renewal_checker_mcp")
async def renewal_checker_mcp(p_body: RenewalCheckerMCP):
    """
    Reads the extracted JSON from the provided Blob URL (or uses provided RawJson),
    compares against local mock Excel, and returns classification result.
    """
    try:
        if p_body.RawJson:
            result = await asyncio.to_thread(run_once_json, p_body.AgentName, p_body.RawJson)
            return JSONResponse(
                content={
                    "jsonrpc": "2.0",
                    "id": 1,
                    "result": result
                }
            )

        container_name, blob_path = _parse_blob_url(p_body.BlobUrl)
        result = await asyncio.to_thread(run_once, p_body.AgentName, container_name, blob_path)
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "result": result
            }
        )
    except Exception as e:
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "result": {"status": False, "Justification": str(e)}
            },
            status_code=200
        )

class CompareRequest(BaseModel):
    """
    This endpoint is invoked by the Data Extraction Agent.
    It passes the FULL Azure Blob URL of the extracted JSON in 'jsonfilepath'.

    Example payload:
    {
      "jsonfilepath": "https://<account>.blob.core.windows.net/<container>/<path>/file.json"
    }

    The service will:
    - Download that JSON from Azure Blob using AZURE_STORAGE_CONNECTION_STRING,
    - Extract the name from Owner/Insured/Contact/NAMED INSURED(S),
    - Compare it against local 'input/sanctions.csv',
    - Return the comparison result in a JSON-RPC envelope (consistent with your duplicate attachment checker).
    """
    jsonfilepath: str = Field(..., description="Full Azure Blob URL to the extracted JSON.")


@router.post(
    "/Licensing_and_Sanction_Checker_MCP",
    operation_id="Licensing_and_Sanction_Checker_MCP",
    summary="Compare JSON (Owner/Insured/Contact/NAMED INSURED(S)) from blob URL with local sanctions CSV."
)
async def compare_files(request: CompareRequest):
    """
    Receives the JSON blob URL from the Data Extraction Agent and performs the comparison.
    Returns a JSON-RPC envelope for consistency with the duplicate attachment checker.
    """
    try:
        result = await compare_name_with_sanctions(json_file_url=request.jsonfilepath)
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "result": result
            },
            status_code=200
        )
    except Exception as e:
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "result": {"status": False, "error": f"Unexpected server error: {str(e)}"}
            },
            status_code=200
        )



# risk score calculator mcp 
class RiskScoreRequest(BaseModel):
    """Trigger risk score computation for a JSON file located in blob storage."""
    AgentName: str = Field(
        default="RiskCalculatorAgent",
        description="The unique agent name of the agent that is being called"
    )
    BlobUrl: str = Field(
        ...,
        description="Required: full blob URL (https://...) or container/blob path (container/path/to/file.json) to analyze"
    )

    @validator("BlobUrl")
    def bloburl_must_not_be_empty(cls, v: str) -> str:
        if not v or not v.strip():
            raise ValueError("BlobUrl must be a non-empty string pointing to the blob (full URL or container/blob path).")
        return v.strip()


@router.post("/risk_score", operation_id="risk_score_calculator_mcp")
async def risk_score(p_body: RiskScoreRequest):
    """
    Compute risk score from JSON in Azure Blob storage using RuleBasedRiskCalculator
    and return the structured result with stubbed Excel row + blob URLs.

    Body:

        AgentName (str): Agent name (optional)

        BlobUrl (str): Required full blob URL or container/blob path.
    """
    try:
        # Call the helper method you added in riskcalculator.py
        result = calculator.process_blob(p_body.BlobUrl)

        return JSONResponse(content={
            "jsonrpc": "2.0",
            "id": 1,
            "result": result
        })

    except Exception as e:
        return JSONResponse(status_code=500, content={"error": f"Risk score computation failed: {e}"})

    


    
class JsonReadRequest(BaseModel):
    """ 
    This endpoint is invoked by an Agent. 
    It passes the FULL Azure Blob URL of the JSON in 'json_blob_url'. 
    The URL must point to the blob folder/prefix where document_extract_mcp stores its output JSON files.

Example payload:
{
  "json_blob_url": "https://<account>.blob.core.windows.net/<container>/<path>/file.json"
}

The service will:
- Validate the URL format is a fully qualified Azure Blob HTTPS URL.
- Validate that the URL host account matches AZURE_STORAGE_ACCOUNT_NAME.
- Enforce that the blob path resides under the configured document_extract_mcp output folder/prefix within the target container.
- Download the JSON from Azure Blob using AZURE_STORAGE_CONNECTION_STRING.
- Confirm the blob exists and is a JSON document (by extension/content-type).
- Parse the blob content into a JSON object.
- Return the full JSON wrapped in a JSON-RPC envelope.

Notes:
- The service uses the connection string for authentication; SAS tokens in the URL are not required and, if present, are ignored.
- Requests for blobs outside the document_extract_mcp output folder/prefix, from other accounts, or non-JSON blobs will be rejected.
- The JSON-RPC envelope will include jsonrpc: "2.0" and place the original JSON inside the result field; an id may be echoed if supplied by the caller.
"""
    json_blob_url: str = Field(..., description="Full Azure Blob URL to the JSON file.")


@router.post(
    "/Json_Reader_MCP",
    operation_id="Json_Reader_Read",
    summary="Fetch and return the full JSON from Azure Blob by URL."
)
async def read_json_from_blob(request: JsonReadRequest):
    """
    Receives a JSON blob URL and returns the full JSON in a JSON-RPC envelope.
    """
    try:
        result = await retrieve_full_json(json_url=request.json_blob_url)
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "result": result
            },
            status_code=200
        )
    except Exception as e:
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "result": {"status": False, "error": f"Unexpected server error: {str(e)}"}
            },
            status_code=200
        )
    
# pydantic class and router for accept_reject_risk_functionality_mcp
 
class ProcessRiskRequest(BaseModel):
    """
    Accept/Reject Risk Functionality MCP
    Input (fixed):
      - Container: risk-score-output
      - The latest blob (by last_modified) will be selected automatically.
    Output (timestamped per run):
      - Container: accept-reject-riskfunctionality-output
      - Blob: accept-reject-riskfunctionality-output_<UTC timestamp>.json
    """
    input_blob_url: str = Field(..., description="Azure Blob URL pointing to the risk-score-output container (any blob path within it is acceptable).")
    acceptance_threshold: float = Field(40.0, description="Optional acceptance threshold (default 75.0).")
    rejection_threshold: float = Field(75.0, description="Optional rejection threshold (default 40.0).")
    earthquake_count: int = Field(description="earthquake count provided by risk_data_capture_mcp.")
    flood_zone: bool = Field(description="flood zone provided by risk_data_capture_mcp.")
    construction_type: str = Field(description="construction type provided by risk_data_capture_mcp.")
    distance_to_fire_hydrant: str = Field(description="distance to fire hydrant provided by risk_data_capture_mcp.")
    distance_to_fire_station: str = Field(description="distance to fire station provided by risk_data_capture_mcp.")
    year_built: int = Field(description="year built provided by risk_data_capture_mcp.")

@router.post(
    "/Accept_Reject_Risk_Functionality_MCP",
    operation_id="accept_reject_risk_functionality_mcp",
    summary="Process latest risk submissions from risk-score-output and write timestamped results to accept-reject-riskfunctionality-output"
)
async def accept_reject_risk_mcp(request: ProcessRiskRequest):
    """
    Evaluates accept/reject decisions, saves local output/results.json,
    and uploads to accept-reject-riskfunctionality-output/<timestamp>.json.
    Returns a JSON-RPC envelope.
    """
    thresholds = RiskThresholds(
        acceptance_threshold=request.acceptance_threshold,
        rejection_threshold=request.rejection_threshold,
    )
 

    result = await process_risk_from_blob(
        input_blob_url=request.input_blob_url,
        construction_type=request.construction_type,
        thresholds=thresholds,
        earthquake_count=request.earthquake_count,
        flood_zone=request.flood_zone,
        distance_to_fire_hydrant=request.distance_to_fire_hydrant,
        distance_to_fire_station=request.distance_to_fire_station,
        year_built=request.year_built,
    )
    return JSONResponse(
        content={"jsonrpc": "2.0", "id": 1, "result": result},
        status_code=200
    )
 


# risk data capture
class RiskDataCaptureRequest(BaseModel):
    """
    This endpoint is used to retrieve the relevant risk data associated with a given address.
    It will:
    - Read the JSON file from Azure Blob,
    - Parse the extracted fields to identify the address,
    - Call an external geocoding API to derive latitude and longitude from the address,
    - Call an external earthquake API to calculate the earthquake count based on the derived latitude/longitude,
    - Stub additional risk-related values using randomized functions:
        • Flood zone
        • Construction type
        • Distance to fire hydrant
        • Distance to fire station
        • Year built
    - Return the risk profile in a JSON format.    
    """
    AgentName: str = Field(default="RiskAssesmentAgent", description=("The unique agent name of the agent that is being called"))
    UserId: str = Field(default="markRuffalo", description=("The unique user id of a specific user (default: 'markRuffalo')."))
    file_path: str = Field(..., description="Full blob URL or plain filename for the JSON file.")
 
@router.post("/risk_data_capture_mcp", operation_id="risk_data_capture_mcp")
async def get_risk_data(p_body: RiskDataCaptureRequest):
    """
    Accepts the JSON blob URL from the Data Extraction Agent, processes the file contents to retrieve relevant risk data.
    
    Args:
        AgentName (str): The unique agent name of the agent that is being called.
        UserId (str): The unique user id of a specific user (default: 'markRuffalo').
        file_path (str): Full blob URL or plain filename for the JSON file.
    """
    try:
        result = await capture_risk_data(p_body.file_path)
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "result": result
            },
            status_code=200
        )
    except Exception as e:
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "error": str(e)
            },
            status_code=500
        )





#attachment_summary_mcp

        
class AttachmentSummaryRequest(BaseModel):
    """
    Payload:
    {
      "attachment_urls": [
        "https://<account>.blob.core.windows.net/<container>/<path>/file1.pdf",
        "https://<account>.blob.core.windows.net/<container>/<path>/file2.pdf"
      ]
    }
    """
    attachment_urls: List[str] = Field(
        ...,
        description="List of full Azure Blob URLs to the PDF attachments returned by the 'email_attachment_mcp'."
    )


@router.post(
    "/attachment_summary_mcp",
    operation_id="attachment_summary_mcp",  # must match main.py include_operations
    summary="Download one or more PDFs from blob, analyze first page and return summaries",
)
async def document_summarizer(request: AttachmentSummaryRequest):
    """
    Processes a list of blob URLs from the email_attachment_mcp and analyzes the documents to generate a summary of the *first page* of each document.
    Args:
    request (AttachmentSummaryRequest): The input request containing a list of blob URLs.

    Returns JSON-RPC style result:
    {
      "jsonrpc": "2.0",
      "id": 1,
      "result": {
        "status": true/false,
        "summaries": [
          {
            "blob_url": "...",
            "file_name": "...",
            "summary": "...",
            "error": null or "message"
          },
          ...
        ],
        "save_error": "..." (optional)
      }
    }
    """
    try:
        result = await summarize_blob_pdfs_layout(request.attachment_urls)
        return JSONResponse(
            content={"jsonrpc": "2.0", "id": 1, "result": result},
            status_code=200,
        )
    except Exception as e:
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "result": {"status": False, "error": str(e)},
            },
            status_code=200,
        )



# Document_query_mcp

class QueryPdfVectorizerMCP(BaseModel):
    """Represents the functionality of vectorizing PDFs and storing them in vector DB"""
    AgentName: str = Field(default="PdfVectorizerAgent", description="The unique agent name of the agent that is being called")
    UserId: str = Field(default="markRuffalo", description="The unique user id of a specific user")
    # BlobUrl: str = Field(..., description="Full blob URL (http(s)://) to the PDF file")
    attachment_urls: List[str] = Field(..., description="List of full Azure Blob URLs to the PDF/DOCX attachments returned by the 'email_attachment_mcp'.")


class QueryRetrieverMCP(BaseModel):
    """Represents the functionality of querying vectorized PDFs for answers"""
    AgentName: str = Field(default="RetrieverAgent", description="The unique agent name of the agent that is being called")
    UserId: str = Field(default="markRuffalo", description="The unique user id of a specific user")
    VectorDbPath: str = Field(..., description="Path to the vector database (local absolute path from pdf_vectorizer output metadata, e.g., /home/.../data/vec_db/pdf_name). If blob URL is received, it will be converted to local path.")
    Query: str = Field(..., description="User's question as a string to be answered from the vectorized PDF content")

@router.post("/query_pdf_vectorizer_mcp", operation_id="query_pdf_vectorizer_mcp")
async def query_pdf_vectorizer_mcp(
    p_body: QueryPdfVectorizerMCP,
):
    """Vectorize one or more PDFs/DOCXs from blob storage and save embeddings to single Chroma vector DB.
    
    Args:
        p_body (QueryPdfVectorizerMCP): Request body containing list of blob URLs
    
    Returns:
        JSONResponse: Contains vectorization status and metadata for all files
    """
    try:
        result = await process_query_pdf(blob_urls=p_body.attachment_urls)
        
        return JSONResponse(content={
            "jsonrpc": "2.0",
            "id": 1,
            "result": result
        })
        
    except Exception as e:
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "error": {
                    "code": 500,
                    "message": f"Error vectorizing PDFs: {str(e)}"
                }
            },
            status_code=500
        )

@router.post("/query_retriever_mcp", operation_id="query_retriever_mcp")
async def query_retriever_mcp(
    p_body: QueryRetrieverMCP,
):
    """Query vectorized PDF and get answers to user questions.
    
    Args:
        p_body (QueryRetrieverMCP): Request body containing vector DB path and user query
    
    Returns:
        JSONResponse: Contains answer and metadata
    """
    try:
        result = await process_query_retrieval(
            vector_db_path=p_body.VectorDbPath,
            query=p_body.Query
        )
        
        return JSONResponse(content={
            "jsonrpc": "2.0",
            "id": 1,
            "result": result
        })
        
    except Exception as e:
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "error": {
                    "code": 500,
                    "message": f"Error processing query: {str(e)}"
                }
            },
            status_code=500
        )


# Email writer mcp

class PropertyDetails(BaseModel):
    """Property details from email"""
    property_name: str = Field(..., description="Name of the property")
    property_address: str = Field(..., description="Address of the property")
    property_type: str = Field(..., description="Type of property")
    broker_name: str = Field(default="N/A", description="Broker/Agent name")
    customer_name: str = Field(default="N/A", description="Customer name")


# class Attachment(BaseModel):
#     """Email attachment information"""
#     filename: str = Field(..., description="Name of the attachment")
#     size: int = Field(..., description="Size of the attachment in bytes")
#     content_type: str = Field(..., description="MIME type of the attachment")
#     blob_url: Optional[str] = Field(default=None, description="Blob storage URL of the attachment")

class Attachment(BaseModel):
    """Email attachment information"""
    filename: str = Field(..., description="Name of the attachment")
    type: str = Field(..., description="Type of attachment")
    size: Optional[int] = Field(default=None, description="Size of the attachment in bytes")
    content_type: Optional[str] = Field(default=None, description="MIME type of the attachment")
    blob_url: Optional[str] = Field(default=None, description="Blob storage URL of the attachment")

class EmailData(BaseModel):
    """Email data extracted from Gmail"""
    reference_id: str = Field(..., description="Unique reference ID from email")
    subject: str = Field(..., description="Email subject")
    body_bloburl: str = Field(..., description="Blob storage URL of email body")
    sender: str = Field(..., description="Sender email address")
    received_date: str = Field(..., description="Date and time email was received")
    has_attachments: bool = Field(default=False, description="Whether email has attachments")
    attachments: List[Attachment] = Field(default_factory=list, description="List of attachments")
    property_details: PropertyDetails = Field(..., description="Property details extracted from email")


class EmailWriterMCP(BaseModel):
    """Email Writer MCP - writes email data to Excel"""
    AgentName: str = Field(default="EmailWriterAgent", description="The unique agent name")
    UserId: str = Field(default="system", description="The unique user id")


@router.post("/write_email_to_excel", operation_id="write_email_to_excel")
async def write_email_to_excel(email_data: EmailData):
    """
    Write extracted email data to Excel file in blob storage
    
    This endpoint takes email metadata extracted by the Email MCP and writes it to an Excel file
    stored in Azure blob storage. Each call appends a new row to the Excel file.
    
    Args:
        email_data (EmailData): Extracted email data with property details
    
    Returns:
        JSONResponse: Contains write status and metadata
    """
    try:
        # Convert Pydantic model to dict
        email_dict = email_data.dict()
        
        # Call the writer function
        result = write_email_data_to_excel(email_dict)
        
        return JSONResponse(content={
            "jsonrpc": "2.0",
            "id": 1,
            "result": {
                "is_written": result["is_written"],
                "error": result["error"],
                "excel_file": result["excel_file"],
                "rows_count": result["rows_count"],
                "reference_id": email_data.reference_id
            }
        })
        
    except Exception as e:
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "error": {
                    "code": 500,
                    "message": f"Error writing email to Excel: {str(e)}"
                }
            },
            status_code=500
        )
