import os
import json
import pandas as pd
from io import BytesIO
from azure.storage.blob import BlobServiceClient
from typing import List, Dict, Any
from summary_service import summary_require_env
from summary_service import AZURE_STORAGE_CONNECTION_STRING, _parse_blob_url


def extract_filenames_and_summaries(output_folder: str) -> List[Dict[str, Any]]:
    """
    Extracts file names and summaries from the JSON file in the output folder.

    Args:
        output_folder (str): The folder where the JSON result file is stored.

    Returns:
        List[Dict[str, Any]]: A list of dictionaries containing file names and summaries.
                              Each dictionary has the structure:
                              {
                                  "file_name": "<file_name>",
                                  "summary": "<summary>"
                              }
    """
    result_file = os.path.join(output_folder, "layout_summaries_result.json")

    if not os.path.exists(result_file):
        raise FileNotFoundError(f"No JSON result file found at {result_file}")

    with open(result_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    summaries = data.get("summaries", [])

    extracted_data = [
        {"file_name": item["file_name"], "summary": item["summary"]}
        for item in summaries
        if "file_name" in item and "summary" in item
    ]

    return extracted_data


def beautify_extracted_data(extracted_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Beautifies and prints the extracted data in the desired format.

    Args:
        extracted_data (List[Dict[str, Any]]): A list of dictionaries containing file names and summaries.

    Returns:
        List[Dict[str, Any]]: A list of dictionaries with added reference numbers.
                              Each item:
                              {
                                "reference_number": "<prefix_before_first_underscore>",
                                "file_name": "<file_name>",
                                "summary": "<summary>"
                              }
    """
    beautified_data: List[Dict[str, Any]] = []

    for item in extracted_data:
        # Extract the reference number from the file_name
        file_name = item["file_name"]
        # Example file_name:
        #   "19AC3EFE6607246C_attachment_Acord125CommInsApp_02.pdf"
        # reference_number -> "19AC3EFE6607246C"
        reference_number = file_name.split("_")[0]

        beautified_item = {
            "reference_number": reference_number,
            "file_name": file_name,
            "summary": item["summary"],
        }
        beautified_data.append(beautified_item)

        # Print the beautified output (for debugging/logs)
        print(f"file_name: {file_name}")
        print(f"reference_number: {reference_number}")
        print(f"summary: {item['summary']}\n")

    # âœ… IMPORTANT: return AFTER the loop, so ALL items are included
    return beautified_data


def connect_to_blob(blob_url: str, beautified_data: List[Dict[str, Any]]):
    """
    Update existing rows in the Excel blob by concatenating file_name + summary
    into the Summary cell for matching 'Unique refrence Number'.
    Does NOT create new rows if there is no match.
    """
    try:
        summary_require_env()
    except Exception as e:
        return {"status": False, "error": f"Environment misconfigured: {e}"}

    if not AZURE_STORAGE_CONNECTION_STRING:
        raise RuntimeError("AZURE_STORAGE_CONNECTION_STRING not set")

    try:
        container, blob_path = _parse_blob_url(blob_url)
    except Exception as e:
        return {"status": False, "error": f"Unable to parse blob URL: {e}"}

    try:
        blob_service_client = BlobServiceClient.from_connection_string(AZURE_STORAGE_CONNECTION_STRING)
        blob_client = blob_service_client.get_blob_client(container=container, blob=blob_path)

        blob_data = blob_client.download_blob().readall()
        excel_data = pd.read_excel(BytesIO(blob_data))

        # Require the Unique reference Number column to exist; do not create rows if missing
        if "Unique refrence Number" not in excel_data.columns:
            return {"status": False, "error": "'Unique refrence Number' column is missing in the Excel file."}

        if "Summary" not in excel_data.columns:
            # create Summary column if missing, but still do not create new rows
            excel_data["Summary"] = None

        for item in beautified_data:
            reference_number = item.get("reference_number")
            file_name = item.get("file_name", "")
            summary_text = item.get("summary", "")

            # find matching rows (there may be multiple, update all matches)
            matches = excel_data[excel_data["Unique refrence Number"] == reference_number].index

            if matches.empty:
                # do not create new rows; just log/skip
                print(f"Reference number not found in Excel, skipping: {reference_number}")
                continue

            # build the new fragment for this attachment
            # NOTE: using '\\n' gives literal "\n" in the cell. If you want real line breaks,
            # change '\\n' to '\n'.
            new_fragment = f"file_name: {file_name}\\nsummary: {summary_text}"

            for idx in matches:
                existing = excel_data.at[idx, "Summary"]
                if existing and not pd.isna(existing):
                    # append separated by blank line for readability
                    updated = f"{existing}\\n\\n{new_fragment}"
                else:
                    updated = new_fragment
                excel_data.at[idx, "Summary"] = updated

        # save back to bytes and upload (overwrite)
        output_stream = BytesIO()
        excel_data.to_excel(output_stream, index=False, engine="openpyxl")
        output_stream.seek(0)
        blob_client.upload_blob(output_stream, overwrite=True)

        return excel_data

    except Exception as e:
        return {"status": False, "error": f"Failed to process blob: {e}"}
