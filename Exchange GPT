import os
import json
from dotenv import load_dotenv
from openai import AzureOpenAI

# ------------------ CONFIG ------------------
load_dotenv()

client = AzureOpenAI(
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    api_version="2024-05-01-preview"
)

MODEL = os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT")
output_dir = os.path.join(os.getcwd(), "output")
INPUT_FILE = os.path.join(output_dir, "output.json")

os.makedirs(output_dir, exist_ok=True)
OUTPUT_FILE = os.path.join(output_dir, "final_output.json")
MAX_CHARS = 12000


def chunk_text(text, max_chars=MAX_CHARS):
    """
    Split long text into safe chunks for OpenAI input.
    We split by lines so we don't cut in the middle of words.
    """
    chunks, current, length = [], [], 0
    for line in text.splitlines():
        if length + len(line) > max_chars:
            chunks.append("\n".join(current))
            current, length = [], 0
        current.append(line)
        length += len(line)
    if current:
        chunks.append("\n".join(current))
    return chunks


def clean_field_name(name: str) -> str:
    """
    Normalize a field name so that:
      'LOB - Commercial Property' -> 'Commercial Property'
      'loss summary' -> 'Loss Summary'
    This helps us match GPT field names with Azure confidence entries.
    """
    if not isinstance(name, str):
        return str(name)

    name = name.replace("LOB -", "").strip()
    return name.title()


def build_confidence_lookup(raw_json):
    """
    Build a lookup:
        { 'Loss Summary': 0.487, 'Commercial Property': 0.975, ... }
    from Azure Document Intelligence 'fields'.
    We will use ONLY these numbers, not the values.
    """
    lookup = {}
    docs = raw_json.get("documents", [])
    if not docs:
        return lookup

    for doc in docs:
        for key, value in doc.get("fields", {}).items():
            conf = value.get("confidence")
            if conf is not None:
                lookup[clean_field_name(key)] = conf

    return lookup


def build_prompt(content_chunk: str) -> str:
    """
    Prompt that tells GPT:
      - Read only this OCR text ('FORM_TEXT')
      - Extract structured JSON with logical groups
      - DO NOT include confidence numbers (Python will attach them later)
    """
    return f"""
You are a JSON data extractor for an ACORD Commercial Insurance Application (ACORD 125).

You will be given plain text content produced by OCR (Azure Document Intelligence).
Using ONLY this text, extract and group information into a single JSON object.

VERY IMPORTANT RULES:
1. Read only the text under "FORM_TEXT". Do not assume anything that is not written there.
2. Create logical top-level groups, for example (names are suggestions, you can add more):
   - "General Information"
   - "Policy Information"
   - "Transaction Status"
   - "Line Of Business"
   - "Premiums"
   - "Attachments"
   - "Insured"
   - "Premises Information"
   - "Nature Of Business"
   - "Additional Interest"
   - "Prior Carrier Information"
   - "Loss History"
   - "Signatures And Producer Information"
   - "Risk And Insurance History"
   - "Safety Program"
   - "Business Ventures"
3. For each field, use the exact value from the text.
   - For checkboxes, copy ':selected:' and ':unselected:' exactly as they appear in the text.
   - Do NOT invent or guess checkbox states.
4. DO NOT add any confidence values in your output.
   - Just output the raw values like "Quote", ":selected:", "11/05/2025", etc.
5. Return ONLY valid JSON. No comments, no explanations, no markdown.

FORM_TEXT:
{content_chunk}
"""


def process_chunk(content_chunk: str):
    """Send one OCR content chunk to GPT and ensure JSON-only output."""
    response = client.chat.completions.create(
        model=MODEL,
        temperature=0,
        messages=[
            {
                "role": "system",
                "content": "You are a precise document understanding assistant that outputs only JSON.",
            },
            {"role": "user", "content": build_prompt(content_chunk)},
        ],
    )

    text = response.choices[0].message.content.strip()
    try:
        start = text.find("{")
        end = text.rfind("}") + 1
        json_text = text[start:end]
        return json.loads(json_text)
    except Exception:
        print("⚠️ Warning: GPT output not clean JSON. Attempting recovery.")
        return {"error": "Invalid JSON returned", "raw_output": text}


def calculate_overall_confidence(original_json):
    """
    Calculate overall average confidence directly from original JSON
    (we use all 'confidence' keys found in Azure's response).
    """

    def extract_confidences(obj):
        confidences = []
        if isinstance(obj, dict):
            for key, value in obj.items():
                if key == "confidence" and isinstance(value, (int, float)):
                    confidences.append(value)
                else:
                    confidences.extend(extract_confidences(value))
        elif isinstance(obj, list):
            for item in obj:
                confidences.extend(extract_confidences(item))
        return confidences

    confidences = extract_confidences(original_json)
    if confidences:
        return sum(confidences) / len(confidences)
    return None


def attach_confidences(data, confidence_lookup):
    """
    Recursively walk the GPT JSON.
    For each leaf field:
      - Look up a confidence by cleaned field name.
      - If found, transform:
            "Some Field": "Value"
        into:
            "Some Field": "Value, confidence - 0.873"
      - If not found, leave as-is.
    """
    if isinstance(data, dict):
        new_obj = {}
        for key, value in data.items():
            if isinstance(value, (dict, list)):
                new_obj[key] = attach_confidences(value, confidence_lookup)
            else:
                clean_key = clean_field_name(key)
                conf = confidence_lookup.get(clean_key)
                if conf is not None:
                    new_obj[key] = f"{value}, confidence - {conf}"
                else:
                    new_obj[key] = value
        return new_obj

    elif isinstance(data, list):
        return [attach_confidences(item, confidence_lookup) for item in data]

    else:
        # primitive type (str/int/float/bool) — nothing to attach
        return data


def add_confidence_averages(grouped_data, confidence_lookup):
    """
    For each top-level group (e.g. "Attachments", "Line Of Business"),
    collect all confidences of fields under it and compute 'total_confidence'.
    """

    def collect_confs(obj):
        collected = []
        if isinstance(obj, dict):
            for k, v in obj.items():
                if k == "total_confidence":
                    continue
                if isinstance(v, (dict, list)):
                    collected.extend(collect_confs(v))
                else:
                    clean_k = clean_field_name(k)
                    c = confidence_lookup.get(clean_k)
                    if c is not None:
                        collected.append(c)
        elif isinstance(obj, list):
            for item in obj:
                collected.extend(collect_confs(item))
        return collected

    for group, fields in grouped_data.items():
        if not isinstance(fields, dict):
            continue
        confs = collect_confs(fields)
        if confs:
            avg_conf = sum(confs) / len(confs)
            fields["total_confidence"] = avg_conf

    return grouped_data


def process_azure_output(json_data):
    """
    Main pipeline:

    1. Take OCR text from Azure 'content' (top-level) if present,
       otherwise from 'documents[0].content' if that exists.
    2. Ask GPT to parse it into structured JSON (values from content only).
    3. Attach confidence numbers from Azure 'fields'.
    4. Compute per-group total_confidence and Document_Confidence_Score.
    5. Save final_output.json.
    """
    # 1. Get OCR text
    # First preference: top-level 'content' (as in your output.json)
    content_text = json_data.get("content", "")

    # Fallback: 'documents[0].content' if top-level 'content' is missing/empty
    if not content_text:
        docs = json_data.get("documents", [])
        if docs and isinstance(docs[0], dict):
            content_text = docs[0].get("content", "")

    if not content_text:
        raise ValueError("No 'content' text found in Azure output JSON.")

    # 2. Chunk the content if too long and process via GPT
    chunks = chunk_text(content_text)
    final_combined = {}

    for chunk in chunks:
        result = process_chunk(chunk)
        if isinstance(result, dict):
            for k, v in result.items():
                if (
                    k in final_combined
                    and isinstance(final_combined[k], dict)
                    and isinstance(v, dict)
                ):
                    final_combined[k].update(v)
                else:
                    final_combined[k] = v

    # 3. Build confidence lookup from Azure fields (only numbers)
    confidence_lookup = build_confidence_lookup(json_data)

    # 4. Attach "..., confidence - X" to leaf fields
    final_with_conf = attach_confidences(final_combined, confidence_lookup)

    # 5. Add total_confidence per top-level group
    final_with_conf = add_confidence_averages(final_with_conf, confidence_lookup)

    # 6. Add overall document-level average confidence
    overall_avg = calculate_overall_confidence(json_data)
    if overall_avg is not None:
        final_with_conf["Document_Confidence_Score"] = overall_avg

    # 7. Save final_output.json
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(final_with_conf, f, indent=2, ensure_ascii=False)

    print(f"✅ Clean JSON written to {OUTPUT_FILE}")
    return final_with_conf


# ------------------ MAIN ------------------
if __name__ == "__main__":
    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        raw_json = json.load(f)

    process_azure_output(raw_json)
