Nice — your logic is correct: beautify_extracted_data() already produces reference_number for each file, so you can use those reference IDs to build the blob names and download the corresponding email body files (which, in your example, live at container=attachment-downloader and follow the filename pattern body_<REF>.txt).

Below I give you a ready-to-copy async function you can add to summary_storage_utils.py plus a short usage snippet to add into summary_handler.py. The function:
	•	Accepts the beautified list (the beautify_data you already have).
	•	Extracts unique reference numbers.
	•	Builds blob name body_{ref}.txt and container attachment-downloader.
	•	Downloads each blob asynchronously into an email_body folder (creates it).
	•	Returns a dict mapping ref -> {"status":"ok","path":local_path} or ref -> {"status":"error","error":message} so you can inspect what succeeded/failed.

Drop this into summary_storage_utils.py (near your existing download_blob_to_input_folder function):

# summary_storage_utils.py  (append this function)

import os
import aiofiles
from azure.storage.blob.aio import BlobServiceClient
from azure.core.exceptions import ResourceNotFoundError, AzureError

from summary_service import AZURE_STORAGE_CONNECTION_STRING, _parse_blob_url  # ensure these exist

async def download_blob_to_input_folder_by_reference(
    beautified_data: list,
    output_folder: str = "email_body",
    container_name: str = "attachment-downloader",
    blob_name_template: str = "body_{ref}.txt",
) -> dict:
    """
    Download blobs whose names are derived from reference numbers found in beautified_data.

    Args:
      beautified_data: list of dicts each containing "reference_number" (as produced by beautify_extracted_data)
      output_folder: local folder to save downloaded email bodies
      container_name: blob container name (default 'attachment-downloader')
      blob_name_template: template for filename in blob storage, {ref} will be replaced by the reference number

    Returns:
      dict mapping reference_number -> {"status":"ok","path":local_path} or {"status":"error","error":msg}
    """
    results = {}

    if not AZURE_STORAGE_CONNECTION_STRING:
        raise RuntimeError("AZURE_STORAGE_CONNECTION_STRING not set")

    # collect unique references
    refs = set()
    for item in beautified_data or []:
        ref = item.get("reference_number") or item.get("reference") or None
        if ref:
            refs.add(str(ref))

    if not refs:
        return {"status": "no_refs", "message": "No reference numbers found in beautified_data", "details": {}}

    os.makedirs(output_folder, exist_ok=True)

    svc = BlobServiceClient.from_connection_string(AZURE_STORAGE_CONNECTION_STRING)

    async with svc:
        container_client = svc.get_container_client(container_name)
        for ref in refs:
            blob_name = blob_name_template.format(ref=ref)
            local_path = os.path.join(output_folder, blob_name)

            try:
                blob_client = container_client.get_blob_client(blob_name)

                # check existence
                try:
                    await blob_client.get_blob_properties()
                except ResourceNotFoundError:
                    results[ref] = {"status": "error", "error": f"Blob not found: container={container_name} blob={blob_name}"}
                    continue

                stream = await blob_client.download_blob()
                data = await stream.readall()

                # write file async
                async with aiofiles.open(local_path, "wb") as f:
                    await f.write(data)

                results[ref] = {"status": "ok", "path": local_path}
            except AzureError as ae:
                results[ref] = {"status": "error", "error": f"AzureError: {ae}"}
            except Exception as e:
                results[ref] = {"status": "error", "error": str(e)}

    return {"status": "done", "details": results}

How to call it from summary_handler.py

You already compute beautify_data earlier:

# after you compute beautify_data in summary_handler.py

from summary_storage_utils import download_blob_to_input_folder_by_reference

# ensure EMAIL_BODY = "email_body" at top of summary_handler.py

# call it (since it's async, await it)
try:
    download_results = await download_blob_to_input_folder_by_reference(
        beautify_data,
        output_folder=EMAIL_BODY,
        container_name="attachment-downloader",
        blob_name_template="body_{ref}.txt",
    )
    print("Email body download results:", download_results)
except Exception as e:
    print("Failed to download email bodies by reference:", e)

Place that call after you build beautify_data (for example, right after the print(beautify_data) line). That ensures you use the reference numbers produced by your beautifier.

Notes, edge cases & helpful tips
	1.	Blob name pattern — I used body_{ref}.txt because your example URL uses body_19AA119CAE5F6409.txt. If your real naming differs (e.g. body_<ref>.eml or body_<ref>_v2.txt) adjust blob_name_template accordingly.
	2.	Container name — I set attachment-downloader (from your example). If containers vary, either add logic to try multiple containers or pass container name via env var.
	3.	Permissions — ensure AZURE_STORAGE_CONNECTION_STRING used by the service has read permission on the attachment-downloader container.
	4.	Diagnostics — the function returns per-ref results so you can log missing blobs instead of failing the whole pipeline. This avoids the kind of BlobNotFound crash you saw earlier.
	5.	Filename collisions — if multiple refs map to the same blob name (unlikely), the function will overwrite the local file. If you want unique local names, prepend the ref into the local filename or include a timestamp.
	6.	Synchronous call alternative — I implemented async to match your download_blob_to_input_folder. If you prefer a synchronous version for easier testing, tell me and I’ll provide it.

⸻

If you want, I can also:
	•	Paste a full updated summary_storage_utils.py with both download functions together (the existing download_blob_to_input_folder + the new download_blob_to_input_folder_by_reference), or
	•	Provide a synchronous version, or
	•	Change the function to accept a single reference (download one file) rather than a batch.

Which would you like?
