Nice detective work — that error pops up because you passed the cleaned payload (a dict) into beautify_extracted_data() which expects a list of per-file dicts (so it tried for item in extracted_data and then item["file_name"] — Python treated item as a string key and you got string indices must be integers not str).

Fix: don’t reuse beautify_extracted_data() for the cleaned API dict. Instead add a small dedicated beautifier that:
	•	Accepts the cleaned payload (the dict with combined_summary + individualized_summary),
	•	Removes/normalizes control characters (\n, \u2714 etc.),
	•	Produces a nicely readable dict (or list) where each per-file item is human-friendly:

file_name: ...
summary: ...
document_type: ...
processed_summary: ...


	•	Does not include raw text.

Below I give you two things you can copy-paste into your existing summary_handler.py:
	1.	A new helper normalize_text() — removes escape sequences, collapses whitespace and converts the checkmark escape to a real check mark (or removes if you prefer).
	2.	beautify_api_response(cleaned_payload) — converts your cleaned API payload into a nicely formatted structure for printing / returning to users (and returns a new data structure you can use to upload to Excel if you want).
	3.	Show exactly where to call it (replace your current attempt that used beautify_extracted_data(cleaned_payload)).

Copy these functions into summary_handler.py (place them above summarize_blob_pdfs_layout or near the other helpers):

import re
from typing import Iterable

def normalize_text(s: str) -> str:
    """
    Clean and normalize an LLM-produced string:
    - Replace escaped unicode sequences like '\\u2714' with '✔' (or remove)
    - Replace repeated newlines with single newline
    - Trim leading/trailing whitespace on each line and collapse multiple spaces
    - Remove stray carriage returns
    """
    if not s:
        return s
    # if the string contains literal backslash-u (e.g. "\\u2714") turn into the actual char
    try:
        # decode unicode-escapes (only when safe) — but avoid double-decoding valid unicode
        # This will transform "\\u2714" into "✔"
        s = s.encode("utf-8").decode("unicode_escape")
    except Exception:
        # fallback: ignore decoding errors
        pass

    # Convert any ✔ variants (some LLMs produce unicode check) to a single visible symbol
    s = s.replace("\u2714", "✔")
    s = s.replace("\\u2714", "✔")  # literal backslash-u

    # Normalize line endings & whitespace
    s = s.replace("\r\n", "\n").replace("\r", "\n")
    # collapse multiple blank lines to single
    s = re.sub(r"\n\s*\n+", "\n\n", s)
    # trim trailing spaces on each line
    s = "\n".join([ln.strip() for ln in s.split("\n")])
    # collapse more-than-two spaces
    s = re.sub(r"[ ]{2,}", " ", s)
    # final strip
    return s.strip()


def beautify_api_response(cleaned_payload: Dict[str, Any]) -> Dict[str, Any]:
    """
    Take cleaned_payload (the dict you return to API) and produce a
    more human-friendly 'beautified' structure for display or Excel upload.

    Input shape:
      {
        "combined_summary": "<string>",
        "individualized_summary": [
          {"file_name": ..., "summary": ..., "document_type": ..., "processed_summary": ...},
          ...
        ]
      }

    Output shape (dict):
      {
        "combined_summary": "<normalized multi-line string>",
        "individualized_summary": [
           {
             "file_name": "<filename>",
             "summary": "<normalized single-paragraph summary>",
             "document_type": "<ACORD|Loss Run|SOV>",
             "processed_summary": "<normalized multi-line narrative>"
           },
           ...
        ]
      }

    This function **does not** return 'text' or raw LLM outputs with \n escapes.
    """
    out = {"combined_summary": None, "individualized_summary": []}

    combined = cleaned_payload.get("combined_summary")
    out["combined_summary"] = normalize_text(combined) if combined else None

    indiv = cleaned_payload.get("individualized_summary", [])
    beautified_list = []
    if isinstance(indiv, Iterable):
        for item in indiv:
            # defensive: ensure keys exist
            file_name = item.get("file_name")
            summary = item.get("summary")
            doc_type = item.get("document_type")
            processed = item.get("processed_summary")

            beautified_item = {
                "file_name": file_name,
                "summary": normalize_text(summary) if summary else None,
                "document_type": doc_type,
                "processed_summary": normalize_text(processed) if processed else None,
            }
            beautified_list.append(beautified_item)

    out["individualized_summary"] = beautified_list
    return out

Next: replace your current failed beautify block (you had):

    cleaned_payload = clean_result_for_api(result)
    try:
        beautify_data = beautify_extracted_data(cleaned_payload)
        print(beautify_data)
    except Exception as e:
        print(f"Error in beautify / blob step: {e}")

with this — it uses the new function and prints in a friendly way:

    # 9) CLEAN the result for the API and return only the compact payload (no raw text)
    cleaned_payload = clean_result_for_api(result)

    # 10) Beautify the cleaned payload for display / optional downstream writing
    try:
        beautified = beautify_api_response(cleaned_payload)
        # print human-friendly combined summary
        print("\n----- COMBINED SUBMISSION SUMMARY (beautified) -----\n")
        if beautified["combined_summary"]:
            print(beautified["combined_summary"])
        else:
            print("No combined summary available.")

        # print per-document nicely
        print("\n----- INDIVIDUAL DOCUMENT SUMMARIES (beautified) -----\n")
        for doc in beautified["individualized_summary"]:
            print(f"file_name: {doc.get('file_name')}")
            print(f"document_type: {doc.get('document_type')}")
            print("summary:")
            print(doc.get("summary") or "  -")
            print("processed_summary:")
            print(doc.get("processed_summary") or "  -")
            print("-" * 60)

        # If you need the beautified dict for uploading to Excel or returning, it's here:
        # beautified (dict)
    except Exception as e:
        print(f"Error in beautify / blob step: {e}")


⸻

Why this fixes your error and cleans the output
	•	You no longer pass a dict into beautify_extracted_data() (which expects a list) — so the string indices error will stop.
	•	normalize_text() decodes \u2714 sequences and collapses \n into readable paragraphs (keeps newlines for sections).
	•	The final printed output is human-friendly (no literal \n tokens, actual line breaks).
	•	The beautified object still contains machine-friendly fields and can be returned by the API or used to create Excel rows: you simply use beautified["individualized_summary"].

⸻

Optional: if you want the printed processed_summary to be single-paragraph (no headers), change the normalize_text step to replace \n with spaces (I kept newlines so sections remain readable).

⸻

If you want, I can:
	•	Paste the full updated summary_handler.py with these functions integrated exactly in the right spot so you can copy-paste the file (I kept message short to avoid a huge dump).
	•	Or create a tiny test harness that shows how a cleaned_payload will print after beautification, using one of your sample outputs.

Which do you want next — full file replacement or a quick test snippet?
