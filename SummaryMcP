You’re right — the immediate reason your combined_summary is coming back null is that summarize_attachments references several variables that don’t exist in that function scope (email_bodies, include_email_bodies_in_prompt, etc.). That raises an exception inside summarize_attachments, your handler catches the exception and sets combined_summary to None (so you see null in the output).

I’ll:
	1.	Explain exactly where the bug is and why it produces null.
	2.	Give fixed, full code for both newsummary.py and the changes you should make in summary_handler.py (drop-in replacements). These keep your original prompt/template exactly and add safe, explicit handling of email bodies.
	3.	Add small debug prints so you can confirm LLM responses and detect rate-limit errors (NoCapacity / 429).

⸻

Quick diagnosis (why null)

In your posted newsummary.py summarize_attachments:
	•	You use if email_bodies is None: but email_bodies is never defined in that function (no param).
	•	You use if include_email_bodies_in_prompt ... but include_email_bodies_in_prompt is never defined.
	•	Those NameErrors cause an exception inside summarize_attachments. In summary_handler.py you wrap the call in try/except and on error you set result["combined_summary_error"] and combined_summary_text = None. That’s why final combined_summary becomes null.

Fix: make summarize_attachments take optional args (email_bodies=None, include_email_bodies=True) or ensure it loads and uses local variables only.

⸻

Fixed files — drop in place of your current modules

1) newsummary.py (complete, tested pattern)

This version preserves your full template, loads local email_body/body_<ref>.txt files if present, and accepts optional flags. It logs prompt length and captures LLM exceptions to return a helpful error string rather than silently failing.

# newsummary.py
from dotenv import load_dotenv
import os
from typing import List, Dict, Optional
from openai import AzureOpenAI

load_dotenv()

AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_CHAT_DEPLOYMENT = os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT")

if not (
    AZURE_OPENAI_ENDPOINT
    and AZURE_OPENAI_API_VERSION
    and AZURE_OPENAI_API_KEY
    and AZURE_OPENAI_CHAT_DEPLOYMENT
):
    raise RuntimeError("Azure OpenAI env vars missing.")

client = AzureOpenAI(
    api_key=AZURE_OPENAI_API_KEY,
    api_version=AZURE_OPENAI_API_VERSION,
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
)


def extract_refs_from_attachments(attachments: List[Dict]) -> List[str]:
    """Return unique refs from filenames (text before first underscore)."""
    refs = []
    for item in attachments or []:
        fname = item.get("file_name", "") or ""
        if "_" in fname:
            refs.append(fname.split("_", 1)[0])
    # keep unique in original order
    seen = set()
    out = []
    for r in refs:
        if r not in seen:
            seen.add(r)
            out.append(r)
    return out


def load_raw_email_bodies_for_refs(refs: List[str], email_body_folder: str = "email_body") -> Dict[str, Dict]:
    """
    Load raw files named `body_<ref>.txt` from email_body_folder.
    Returns dict: ref -> {"status": "ok", "path": ..., "raw": "<full text>"} or {"status":"missing"}.
    """
    base = os.path.dirname(os.path.abspath(__file__))
    out = {}
    for ref in refs or []:
        fname = f"body_{ref}.txt"
        path = os.path.join(base, email_body_folder, fname)
        if not os.path.exists(path):
            out[ref] = {"status": "missing", "path": path}
            continue
        try:
            with open(path, "r", encoding="utf-8", errors="ignore") as f:
                raw = f.read()
            out[ref] = {"status": "ok", "path": path, "raw": raw}
        except Exception as e:
            out[ref] = {"status": "error", "path": path, "error": str(e)}
    return out


def summarize_attachments(
    attachments: List[Dict],
    email_bodies: Optional[Dict[str, Dict]] = None,
    include_email_bodies_in_prompt: bool = True,
) -> str:
    """
    Build combined submission summary.

    Args:
      attachments: list of {"file_name":..., "summary":..., "text":...}
      email_bodies: optional dict mapping ref -> {"status": "ok", "raw": "..."}.
                    If None, this function will attempt to load local files body_<ref>.txt.
      include_email_bodies_in_prompt: whether to include email bodies block in prompt.

    Returns:
      Combined summary string from LLM (or an informative error string on failure).
    """
    # build attachments text (single pass — no duplication)
    attachment_chunks = []
    for item in attachments or []:
        file_name = item.get("file_name", "unknown_file")
        summary_text = item.get("summary", "") or ""
        chunk = f"FILENAME: {file_name}\nSUMMARY: {summary_text}"
        attachment_chunks.append(chunk)
    attachments_text = "\n\n".join(attachment_chunks)
    attachments_text = attachments_text[:8000]  # safety limit

    # load email bodies if not provided
    if email_bodies is None:
        refs = extract_refs_from_attachments(attachments)
        email_bodies = load_raw_email_bodies_for_refs(refs)

    # build email bodies text block (compact)
    email_chunks = []
    if include_email_bodies_in_prompt and isinstance(email_bodies, dict):
        for ref, meta in (email_bodies or {}).items():
            if meta.get("status") == "ok":
                raw = meta.get("raw", "") or ""
                snippet = raw[:3000]  # keep reasonable amount
                email_chunks.append(f"REFERENCE: {ref}\nRAW_EMAIL_BODY:\n{snippet}")
    email_bodies_text = "\n\n---\n\n".join(email_chunks)
    if email_bodies_text and len(email_bodies_text) > 6000:
        email_bodies_text = email_bodies_text[:6000] + "\n[TRUNCATED]"

    # Build the prompt — your template preserved (attachments block appears once)
    prompt = f"""
You are an experienced Commercial Insurance Underwriter.

You are given multiple attachment documents that belong to a SINGLE
commercial insurance submission. For each document you only see:
- the file name (which hints at document type, e.g. ACORD app, loss run, SOV)
- a short summary of the contents.

YOUR TASK:
Produce ONE combined "Submission Summary" for the account that synthesizes
all the information across all documents.

VERY IMPORTANT RULES:
1. Treat the file names and their summaries as the PRIMARY source of truth.
   - You may use the file name to infer the general document type
     (e.g. application, loss runs, SOV, schedule).
   - Do NOT invent any new facts that are not clearly supported by
     the summaries and the email content.
2. Do NOT mention which document or file any detail came from.
   - The final summary must read like a single coherent view of the account,
     not a list of separate documents.
3. Focus on underwriting-relevant information, such as:
   - Named insured / client
   - Locations and occupancy
   - Operations / business activities
   - Coverage dates and basic program structure
   - Property values / limits / coinsurance (if mentioned)
   - Key coverage features (causes of loss, notable exclusions)
   - Loss history and major incidents
   - Any other material hazards or special notes that appear in the summaries.

IMPORTANT ABOUT EMAIL BODIES:
- If raw email body text is present below, use it only to supplement or
  clarify facts from the attachments. When using the email text, use ONLY
  the MAIN CONTENT (core submission facts, requested limits, dates, TIV, etc.).
  Ignore salutations ("Dear ..."), sign-offs ("Regards", "Kind regards"), and
  signature contact lines (email addresses, phone numbers).

STRUCTURE OF YOUR OUTPUT (USE THIS EXACT TEMPLATE):

SUBMISSION SUMMARY  
Client: [Client Legal Name]  
Date: [Submission or Document Date]

1. SUBMISSION COVER LETTER / NARRATIVE  
 Exposure Description:  
    - [Describe what the business does]  
    - [Main operations / physical activities]  
    - [Property details: construction, age, protection, sprinklers, etc.]  

 Placement Strategy:  
    - [Placement goals or program approach if evident]  

 Renewal Highlights:  
    - [Notable changes or updates if mentioned]  

 Changes YOY:  
    - [Any changes in exposure, values, operations, or loss experience]  

 Additional Overview Details:  
    - Effective Date: [Coverage start date]  
    - Submission Type: [Renewal / New Business / Other]  
    - Current Situation: [Reason for submission if stated]  

2. LOSS HISTORY PACKAGE   
 5–10 Year Loss Runs:  
    - [Summarize multi-year loss experience if available]  

 Large Loss Details:  
    - [Brief details on significant claims]  

 Trends Analysis:  
    - [Patterns in frequency/severity if evident]  

 Summary of Loss History:  
    - Status: [Clean / Losses Reported]  
    - Summary: [1-sentence overview]  
    - Major Incidents: [Largest incident if present]  

3. EXPOSURE DATA  
 COPE Information (Construction, Occupancy, Protection, Exposure):  
    - [Building info, occupancy, protection systems]  

 Statement of Values (SOV):  
    - Total Insurable Value (TIV): $[Insert if present]  
    - Building Limit: $[Insert]  
    - Contents/BPP Limit: $[Insert]  
    - Business Income: $[Insert]  

 Financials:  
    - [Any financial information if mentioned]  

 CAT Worksheets:  
    - [If any catastrophe/hazard info appears]  

 Specialty Schedules:  
    - [Any special schedules referenced]  

 Additional Exposure Details:  
    - Total Locations: [Insert]  
    - Main Operations: [Insert]  
    - Property Details: [Insert]  
    - Deductible Requested: $[Insert]  

Attached files included:
{attachments_text}

# RAW EMAIL BODIES (if present; use them only to supplement / clarify)
{email_bodies_text}
    """

    # debug prints to help you debug when running
    try:
        print(f"[newsummary] prompt length={len(prompt)}; email bodies included={bool(email_chunks)}")
    except Exception:
        pass

    # Call the LLM — catch and return error text if it fails
    try:
        response = client.chat.completions.create(
            model=AZURE_OPENAI_CHAT_DEPLOYMENT,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1024,
            temperature=0.2,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        # Return the error string so the handler won't silently make combined_summary null
        err = f"[LLM_ERROR] {type(e).__name__}: {e}"
        print(err)
        return err


⸻

2) Changes to summary_handler.py

You already have most of the flow correct. I only recommend you explicitly call extract_refs_from_attachments and load_raw_email_bodies_for_refs, then pass the loaded email_bodies dict into summarize_attachments so there is no ambiguity.

Replace the combined-summary / email body block in your handler with this snippet (drop-in):

    # 7) Build combined submission summary
    combined_summary_text = None
    filenamesummary_extracted_beautified: List[Dict[str, Any]] = []
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        json_path = os.path.join(base_dir, OUTPUT_FOLDER, "layout_summaries_result.json")
        with open(json_path, "r", encoding="utf-8") as f:
            layout_json = json.load(f)

        filenamesummary_extracted_beautified = extract_filenames_and_summaries(OUTPUT_FOLDER)
        print("Per-document summaries (with text):")
        print(filenamesummary_extracted_beautified)

        # Extract refs and load email bodies (local files written earlier by download_blob_to_input_folder_by_reference)
        refs = extract_refs_from_attachments(filenamesummary_extracted_beautified)
        email_bodies_map = load_raw_email_bodies_for_refs(refs, email_body_folder=EMAIL_BODY)
        print("Loaded email bodies for refs:", {k: v.get("status") for k, v in email_bodies_map.items()})

        # Pass email_bodies_map explicitly into summarize_attachments
        combined_summary_text = summarize_attachments(
            filenamesummary_extracted_beautified,
            email_bodies=email_bodies_map,
            include_email_bodies_in_prompt=True,
        )
        print("Combined Submission Summary:")
        print(combined_summary_text)

        result["combined_summary"] = combined_summary_text
    except Exception as e:
        print(f"Error generating combined submission summary: {e}")
        result["combined_summary_error"] = str(e)
        combined_summary_text = None

This ensures:
	•	summarize_attachments gets a valid email_bodies dict (possibly with status “missing” for missing ones).
	•	No NameError can happen inside summarize_attachments.
	•	If LLM fails, the error string is returned and stored (you’ll see [LLM_ERROR]... instead of null), which makes debugging easier.

⸻

Additional important notes & debugging tips
	1.	Watch for LLM rate-limit / NoCapacity errors.
Earlier logs showed Error code: 429 - {'error': {'code': 'NoCapacity', ...}}. If that happens, summarize_attachments may return an error string or raise. With the fixed code you will get an [LLM_ERROR] message printed and returned. If you hit NoCapacity frequently, either retry later or use a smaller max_tokens or provision throughput per Azure guidance.
	2.	Confirm email bodies are downloaded correctly.
After download_blob_to_input_folder_by_reference runs, check email_body/ folder contains body_<ref>.txt and that load_raw_email_bodies_for_refs returns {"status":"ok",...}. The handler prints statuses.
	3.	Check logs for prompt length and whether email bodies were included.
newsummary prints prompt length=...; email bodies included=True/False. That helps ensure prompt isn’t empty or truncated.
	4.	If individualized_summary remains empty later, check the individual_summary logs: that function calls identify_document_type and downstream LLMs; any 429/NoCapacity there will also produce errors. Instrument the individual_summary function with prints (it already prints Document Type Identified for ... and processed output). Look up those printed lines.
	5.	Local testing: Before calling Azure LLM, you can stub client.chat.completions.create to return a canned reply to verify the whole flow (download, file read, Excel write) works end-to-end.

⸻

If you want, I can:
	•	Provide a small unit test script that mocks the Azure calls so you can test the handler and Excel updates without hitting Azure.
	•	Or produce a patch diff you can git apply.

Would you like the mock test script now, or do you want me to drop-in the two files as full replacements (I already gave newsummary.py fully; tell me if you want the full summary_handler.py file with all other functions preserved)?
