this is in excel, no matter if the summary is same if there are 2 attachments i want its file name and its summary in excel as well 

file_name: 19AC3EFE6607246C_attachment_Acord125CommInsApp_02.pdfnsummary: This document is a commercial insurance application form submitted by Sunflower Property Group LLC, doing business as Cruise Mall, located in Seabreeze, Florida. The application is managed by Meridian Shoreline Insurance Partners, with Olivia Park as the contact person. It outlines the proposed insurance coverage period from January 1, 2026, to January 1, 2027, and indicates a request for commercial property insurance, among other possible lines of business. Various supplemental attachments and details about the applicant’s business structure are referenced, but specific coverage amounts and carrier information are yet to be determined.


in our json we had 2 file names and 2 summaries but why only this got populated in excel both of them(filename then its summary, filename then its summary,)  should be populated

below is the json 
{
  "status": true,
  "summaries": [
    {
      "blob_url": "https://agenticai1.blob.core.windows.net/attachment-downloader/19AC3EFE6607246C_attachment_Acord125CommInsApp_02.pdf",
      "file_name": "19AC3EFE6607246C_attachment_Acord125CommInsApp_02.pdf",
      "summary": "This document is a commercial insurance application form submitted by Sunflower Property Group LLC, doing business as Cruise Mall, located in Seabreeze, Florida. The application is managed by Meridian Shoreline Insurance Partners, with Olivia Park as the contact person. It outlines the proposed insurance coverage period from January 1, 2026, to January 1, 2027, and indicates a request for commercial property insurance, with other lines of business listed but not selected. The form includes sections for applicant details, business structure, and attachments related to property and loss information, but specific premium amounts and carrier details are yet to be determined.",
      "error": null
    },
    {
      "blob_url": "https://agenticai1.blob.core.windows.net/attachment-downloader/19AC3EFE6607246C_attachment_DummyAcord125CommInsApp_01.pdf",
      "file_name": "19AC3EFE6607246C_attachment_DummyAcord125CommInsApp_01.pdf",
      "summary": "This document is a commercial insurance application form submitted by Sunflower Property Group LLC, doing business as Cruise Mall, located in Seabreeze, Florida. It is prepared by Meridian Shoreline Insurance Partners and lists Olivia Park as the agency contact. The application is primarily for commercial property insurance coverage, with the proposed policy period running from January 1, 2026, to January 1, 2027, and the premium yet to be determined. The form includes applicant details, lines of business considered, and references to various supplemental attachments and schedules relevant to the insurance application process.",
      "error": null
    }
  ]
}


in our json we had 2 file names and 2 summaries but why only 1 got populated in excel both of them(filename then its summary, filename then its summary,)  should be populated in the same row where the reference number has matched under summary column

below is the complete code 

Data_Filler.py


import os
import json
import pandas as pd
from io import BytesIO
from azure.storage.blob import BlobServiceClient
from typing import List, Dict, Any
from summary_service import summary_require_env
from summary_service import AZURE_STORAGE_CONNECTION_STRING, _parse_blob_url



def extract_filenames_and_summaries(output_folder:str)->List[Dict[str,Any]]:
    """
    Extracts file names and summaries from the JSON file in the output folder.

    Args:
        output_folder (str): The folder where the JSON result file is stored.

    Returns:
        List[Dict[str, Any]]: A list of dictionaries containing file names and summaries.
                              Each dictionary has the structure:
                              {
                                  "file_name": "<file_name>",
                                  "summary": "<summary>"
                              }
    """

    result_file = os.path.join(output_folder,"layout_summaries_result.json")

    if not os.path.exists(result_file):
        raise FileNotFoundError(f"NoJSON result file found at {result_file}")
    with open(result_file, "r", encoding="utf-8") as f:
        data = json.load(f)  

    summaries = data.get("summaries", [])
    
    extracted_data = [
        {"file_name": item["file_name"], "summary": item["summary"]}
        for item in summaries
        if "file_name" in item and "summary" in item
    ] 
    return extracted_data
    


#the below function is used for buitifying the file name and summary so that it can be stored in excel    
def beautify_extracted_data(extracted_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Beautifies and prints the extracted data in the desired format.

    Args:
        extracted_data (List[Dict[str, Any]]): A list of dictionaries containing file names and summaries.

    Returns:
        List[Dict[str, Any]]: A list of dictionaries with added reference numbers.
    """
    beautified_data = [] 
    # reference_numbers = []  # List to store all reference numbers

    for item in extracted_data:
        # Extract the reference number from the file_name
        file_name = item['file_name']
        reference_number = file_name.split("_")[0]  # Extract the part before the first underscore
        # reference_numbers.append(reference_number)  # Add to the list of reference numbers


        beautified_item = {
            "reference_number": reference_number,
            "file_name": file_name,
            "summary": item['summary'],
        }
        beautified_data.append(beautified_item)


        # Print the beautified output
        print(f"file_name: {file_name}")
        print(f"reference_number: {reference_number}")
        print(f"summary: {item['summary']}n")
        
        return beautified_data




def connect_to_blob(blob_url: str, beautified_data: List[Dict[str, Any]]):
    """
    Update existing rows in the Excel blob by concatenating file_name + summary
    into the Summary cell for matching 'Unique refrence Number'.
    Does NOT create new rows if there is no match.
    """
    try:
        summary_require_env()
    except Exception as e:
        return {"status": False, "error": f"Environment misconfigured: {e}"}

    if not AZURE_STORAGE_CONNECTION_STRING:
        raise RuntimeError("AZURE_STORAGE_CONNECTION_STRING not set")

    try:
        container, blob_path = _parse_blob_url(blob_url)
    except Exception as e:
        return {"status": False, "error": f"Unable to parse blob URL: {e}"}

    try:
        blob_service_client = BlobServiceClient.from_connection_string(AZURE_STORAGE_CONNECTION_STRING)
        blob_client = blob_service_client.get_blob_client(container=container, blob=blob_path)

        blob_data = blob_client.download_blob().readall()
        excel_data = pd.read_excel(BytesIO(blob_data))

        # Require the Unique reference Number column to exist; do not create rows if missing
        if "Unique refrence Number" not in excel_data.columns:
            return {"status": False, "error": "'Unique refrence Number' column is missing in the Excel file."}

        if "Summary" not in excel_data.columns:
            # create Summary column if missing, but still do not create new rows
            excel_data["Summary"] = None

        for item in beautified_data:
            reference_number = item.get("reference_number")
            file_name = item.get("file_name", "")
            summary_text = item.get("summary", "")

            # find matching rows (there may be multiple, update all matches)
            matches = excel_data[excel_data["Unique refrence Number"] == reference_number].index

            if matches.empty:
                # do not create new rows; just log/skip
                print(f"Reference number not found in Excel, skipping: {reference_number}")
                continue

            # build the new fragment for this attachment
            new_fragment = f"file_name: {file_name}\\nsummary: {summary_text}"

            for idx in matches:
                existing = excel_data.at[idx, "Summary"]
                if existing and not pd.isna(existing):
                    # append separated by blank line for readability
                    updated = f"{existing}\\n\\n{new_fragment}"
                else:
                    updated = new_fragment
                excel_data.at[idx, "Summary"] = updated

        # save back to bytes and upload (overwrite)
        output_stream = BytesIO()
        excel_data.to_excel(output_stream, index=False, engine="openpyxl")
        output_stream.seek(0)
        blob_client.upload_blob(output_stream, overwrite=True)

        return excel_data

    except Exception as e:
        return {"status": False, "error": f"Failed to process blob: {e}"}


main.py

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi_mcp import FastApiMCP
import uvicorn

from router import router as layout_router  # our layout summary router


def apply_cors(app: FastAPI):
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_methods=["*"],
        allow_headers=["*"],
    )


def create_sub_app(title: str, description: str, version: str = "0.1.0") -> FastAPI:
    sub = FastAPI(title=title, description=description, version=version)
    apply_cors(sub)
    return sub


# Root app
app = FastAPI()
apply_cors(app)

# Sub-app for this MCP
layout_app = create_sub_app(
    title="Layout Summary MCP",
    description="Downloads one or more PDFs from Azure Blob, extracts text using Form Recognizer, and summarizes the first page of each document."
)

# Attach our router to the sub-app
layout_app.include_router(layout_router)

# Expose ONLY this operation id via MCP HTTP (client will use transport='http')
# NOTE: operation_id must match the one in router.py (@router.post(..., operation_id="layout_detection_mcp"))
FastApiMCP(layout_app, include_operations=["attachment_summary_mcp"]).mount_http()

# Mount the sub-app under this prefix (similar to your other project)
# Final HTTP endpoint: POST /api/v1/layout_agent/layout_detection_mcp
app.mount("/api/v1/summary_agent", layout_app)


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8602)

router.py



from typing import List
from fastapi import APIRouter
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field

from summary_handler import summarize_blob_pdfs_layout  


router = APIRouter()


class AttachmentSummaryRequest(BaseModel):
    """
    Payload:
    {
      "attachment_urls": [
        "https://<account>.blob.core.windows.net/<container>/<path>/file1.pdf",
        "https://<account>.blob.core.windows.net/<container>/<path>/file2.pdf"
      ]
    }
    """
    attachment_urls: List[str] = Field(
        ...,
        description="List of full Azure Blob URLs to the PDF attachments."
    )


@router.post(
    "/attachment_summary_mcp",
    operation_id="attachment_summary_mcp",  # must match main.py include_operations
    summary="Download one or more PDFs from blob, analyze first page and return summaries",
)
async def document_summarizer(request: AttachmentSummaryRequest):
    """
    Processes a list of blob URLs from the email_attachment_mcp and analyzes the documents to generate a summary of the *first page* of each document.
    Args:
    request (AttachmentSummaryRequest): The input request containing a list of blob URLs.

    Returns JSON-RPC style result:
    {
      "jsonrpc": "2.0",
      "id": 1,
      "result": {
        "status": true/false,
        "summaries": [
          {
            "blob_url": "...",
            "file_name": "...",
            "summary": "...",
            "error": null or "message"
          },
          ...
        ],
        "save_error": "..." (optional)
      }
    }
    """
    try:
        result = await summarize_blob_pdfs_layout(request.attachment_urls)
        return JSONResponse(
            content={"jsonrpc": "2.0", "id": 1, "result": result},
            status_code=200,
        )
    except Exception as e:
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "result": {"status": False, "error": str(e)},
            },
            status_code=200,
        )




summary_classifer.py


from dotenv import load_dotenv
import os
from openai import AzureOpenAI  #  Correct import for Azure OpenAI

# Load environment variables
load_dotenv()

AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_CHAT_DEPLOYMENT = os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT")

if not (
    AZURE_OPENAI_ENDPOINT
    and AZURE_OPENAI_API_VERSION
    and AZURE_OPENAI_API_KEY
    and AZURE_OPENAI_CHAT_DEPLOYMENT
):
    raise RuntimeError(
        "Azure OpenAI env vars missing. Please set "
        "AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_API_VERSION, "
        "AZURE_OPENAI_API_KEY and AZURE_OPENAI_CHAT_DEPLOYMENT"
    )

#  Create Azure OpenAI client
client = AzureOpenAI(
    api_key=AZURE_OPENAI_API_KEY,
    api_version=AZURE_OPENAI_API_VERSION,
    azure_endpoint=AZURE_OPENAI_ENDPOINT,
)


def summarize_first_page(document_content: dict, file_name: str | None = None) -> str:
    """
    Use Azure OpenAI to summarize the *first page* of the document.

    document_content is expected to come from load_document() and contain:
      - "pages": List[str]  # each item = text of a page
      - "text": str         # full text of the document (fallback)
    """

    first_page_text = document_content.get("first_page_text")
    if not first_page_text:
        first_page_text = document_content.get("text", "")

    # Safety: limit size so we don't overload the prompt
    first_page_text = first_page_text[:4000]

    prompt = f"""
You are an expert in insurance documentation.

Your task is to read the FIRST PAGE of an insurance-related PDF and write a concise,
human-readable summary of what this document is about, do not mention the sequence of the page while summarizing.

Document name: {file_name or "Unknown"}

First page content:
\"\"\"{first_page_text}\"\"\"

Write:
- A short paragraph (3–5 sentences)
- No bullet points
- No headings
- No extra explanation, only the summary.
"""

    response = client.chat.completions.create(
        model=AZURE_OPENAI_CHAT_DEPLOYMENT,
        messages=[{"role": "user", "content": prompt}],
        max_tokens=256,
        temperature=0.2,
    )

    try:
        return response.choices[0].message.content.strip()
    except Exception:
        return getattr(response.choices[0].message, "content", "").strip()




summary_handler.py



import os
import json
from typing import Dict, Any, List
import pandas as pd
from summary_service import summary_require_env
from summary_storage_utils import download_blob_to_input_folder
from summary_loader import load_summary_document
from summary_classifier import summarize_first_page
from Data_Filler import extract_filenames_and_summaries
from Data_Filler import connect_to_blob, beautify_extracted_data

INPUT_FOLDER = "input"
OUTPUT_FOLDER = "output"


async def summarize_blob_pdfs_layout(blob_urls: List[str]) -> Dict[str, Any]:
    """
    For each Blob URL:
      - Download PDF into input/
      - Use Form Recognizer to extract text (all pages)
      - Use LLM to summarize the FIRST PAGE

    Returns:
      {
        "status": True/False,
        "summaries": [
          {
            "blob_url": "<url>",
            "file_name": "file1.pdf",
            "summary": "<summary text>" or None,
            "error": "<error message>" or None
          },
          ...
        ],
        "save_error": "<error if we couldn't write output file>"  # optional
      }
    """
    try:
        summary_require_env()
    except Exception as e:
        return {"status": False, "error": f"Environment misconfigured: {e}"}

    summaries: List[Dict[str, Any]] = []

    for blob_url in blob_urls:
        file_name = None

        # 1) Download PDF
        try:
            local_pdf = await download_blob_to_input_folder(
                blob_url, input_folder=INPUT_FOLDER
            )
            file_name = os.path.basename(local_pdf)
        except Exception as e:
            summaries.append(
                {
                    "blob_url": blob_url,
                    "file_name": file_name,
                    "summary": None,
                    "error": f"Failed to download blob: {e}",
                }
            )
            continue

        # 2) Use Form Recognizer to analyze the document
        try:
            document_content = load_summary_document(local_pdf)
        except Exception as e:
            summaries.append(
                {
                    "blob_url": blob_url,
                    "file_name": file_name,
                    "summary": None,
                    "error": f"Form Recognizer failed: {e}",
                }
            )
            continue

        # 3) Summarize FIRST PAGE using LLM
        try:
            summary_text = summarize_first_page(document_content, file_name=file_name)
        except Exception as e:
            summaries.append(
                {
                    "blob_url": blob_url,
                    "file_name": file_name,
                    "summary": None,
                    "error": f"Summarization failed: {e}",
                }
            )
            continue

        # 4) Success case for this document
        summaries.append(
            {
                "blob_url": blob_url,
                "file_name": file_name,
                "summary": summary_text,
                "error": None,
            }
        )

    result: Dict[str, Any] = {"status": True, "summaries": summaries}

    # 5) Save result to ./output (optional, same style as your earlier project)
    try:
        os.makedirs(OUTPUT_FOLDER, exist_ok=True)
        out_path = os.path.join(OUTPUT_FOLDER, "layout_summaries_result.json")
        with open(out_path, "w", encoding="utf-8") as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
    except Exception as e:
        result["save_error"] = str(e)
    
    try:
        extracted_data = extract_filenames_and_summaries(OUTPUT_FOLDER)
        # print("Extracted Data:", extracted_data)
        print("Beautified Extracted Data:\n")
        beautify_data = beautify_extracted_data(extracted_data)

        # Example usage of connect_to_blob
        DATA_URL = os.getenv("Data_URL")  # Retrieve the Data_URL from environment variables
        if DATA_URL:
            try:
                updated_data = connect_to_blob(DATA_URL,beautify_data)
                print("Blob Data Processed Successfully.")
                if isinstance(updated_data, pd.DataFrame):
                    print("Blob Data Processed Successfully and Excel Updated.")
                else:
                    print(f"Error: {updated_data['error']}")
            except Exception as e:
                print(f"Error processing blob data: {e}")
        else:
            print("Data_URL environment variable is not set.")

    except Exception as e:
        print(f"Error: {e}")







    return result



summary_loader.py



from dotenv import load_dotenv
import os
from azure.ai.formrecognizer import DocumentAnalysisClient
from azure.core.credentials import AzureKeyCredential

# Load environment variables from .env file
load_dotenv()

# Fetch variables
endpoint = os.getenv("AZURE_FORMRECOG_ENDPOINT")
key = os.getenv("AZURE_FORMRECOG_KEY")

# Fail fast if missing
if not endpoint:
    raise ValueError("AZURE_FORMRECOG_ENDPOINT is not set. Check your .env file.")
if not key:
    raise ValueError("AZURE_FORMRECOG_KEY is not set. Check your .env file.")

# Create the client using the key and endpoint
client = DocumentAnalysisClient(endpoint=endpoint, credential=AzureKeyCredential(key))


def load_summary_document(file_path: str) -> dict:
    """
    Extract ONLY the text of the FIRST PAGE
    using Form Recognizer's prebuilt-read model.

    Returns a dict with:
      - "first_page_text": text of page 1
    """
    with open(file_path, "rb") as f:
        #  Use prebuilt-read and restrict to first page only
        poller = client.begin_analyze_document(
            "prebuilt-read",
            document=f,
            pages="1",  # tell Form Recognizer we only care about page 1
        )
        result = poller.result()

    # Defensive: make sure we have at least one page
    if not result.pages:
        return {"first_page_text": ""}

    first_page = result.pages[0]
    lines = [line.content for line in first_page.lines]
    first_page_text = "\n".join(lines)

    # Optional debug
    print("First page text (truncated to 500 chars):")
    print(first_page_text[:500])
    print("\n---- END OF FIRST PAGE PREVIEW ----\n")

    return {
        "first_page_text": first_page_text
    }



summary_service.py


import os
from urllib.parse import urlparse, unquote
from dotenv import load_dotenv

load_dotenv()

AZURE_STORAGE_CONNECTION_STRING = os.environ.get("AZURE_STORAGE_CONNECTION_STRING", "")


def summary_require_env() -> None:
    """Ensure required environment variables exist."""
    if not AZURE_STORAGE_CONNECTION_STRING:
        raise RuntimeError("Missing AZURE_STORAGE_CONNECTION_STRING in environment/.env")


def _parse_blob_url(url: str) -> tuple[str, str]:
    """
    Parse an Azure Blob URL and return (container_name, blob_path).
    Example URL:
      https://account.blob.core.windows.net/output-results/folder/name.pdf
    Returns:
      ("output-results", "folder/name.pdf")
    """
    parsed = urlparse(url)
    if not parsed.scheme.startswith("http"):
        raise ValueError("url must be a valid http(s) Azure Blob URL.")

    path = parsed.path.lstrip("/")
    if "/" not in path:
        raise ValueError("url must include both container and blob path.")
    parts = path.split("/", 1)
    container = parts[0]
    blob_path = parts[1]
    return unquote(container), unquote(blob_path)






# summary_storage_utils.py

import os
import aiofiles
from azure.storage.blob.aio import BlobServiceClient
from azure.core.exceptions import ResourceNotFoundError

from summary_service import AZURE_STORAGE_CONNECTION_STRING, _parse_blob_url


async def download_blob_to_input_folder(blob_url: str, input_folder: str = "input") -> str:
    """
    Downloads the blob at blob_url into input_folder (root-level) preserving filename.
    Returns the local path to the downloaded file.
    """
    if not AZURE_STORAGE_CONNECTION_STRING:
        raise RuntimeError("AZURE_STORAGE_CONNECTION_STRING not set")

    container, blob_path = _parse_blob_url(blob_url)
    filename = os.path.basename(blob_path)
    os.makedirs(input_folder, exist_ok=True)
    local_path = os.path.join(input_folder, filename)

    async with BlobServiceClient.from_connection_string(AZURE_STORAGE_CONNECTION_STRING) as service:
        container_client = service.get_container_client(container)
        blob_client = container_client.get_blob_client(blob_path)
        try:
            await blob_client.get_blob_properties()
        except ResourceNotFoundError:
            raise FileNotFoundError(f"Blob not found: container={container} blob={blob_path}")
        stream = await blob_client.download_blob()
        data = await stream.readall()

    # write file async
    async with aiofiles.open(local_path, "wb") as f:
        await f.write(data)

    return local_path

test_script.py


import os
import json
import requests

# Base URL of your FastAPI service
# After main.py starts, the root app listens on port 8602
BASE_URL = os.getenv("LAYOUT_BASE_URL", "http://localhost:8602")

# We mounted the sub-app at /api/v1/layout_agent
# Router path is /layout_detection_mcp
# So final endpoint is:
#   POST http://localhost:8602/api/v1/layout_agent/layout_detection_mcp
ENDPOINT = f"{BASE_URL}/api/v1/summary_agent/attachment_summary_mcp"


def run_test():
    # Example payload: list of blob URLs
    payload = {
        "attachment_urls": [
            "https://agenticai1.blob.core.windows.net/attachment-downloader/19AC3EFE6607246C_attachment_Acord125CommInsApp_02.pdf",
            "https://agenticai1.blob.core.windows.net/attachment-downloader/19AC3EFE6607246C_attachment_DummyAcord125CommInsApp_01.pdf"
            # "https://agenticai1.blob.core.windows.net/attachment-downloader/19AC3EFE6607246C_attachment_Acord_125_Berkshire_Hathway.pdf",
            # "https://agenticai1.blob.core.windows.net/attachment-downloader/19AC48EA9AED3726_attachment_Request_for_Quote_Property_Detailed_Report.pdf"
            # Add more URLs to test multiple documents:
            # "https://agenticail.blob.core.windows.net/attachment-downloader/another.pdf",
        ]
    }

    print(f"Calling endpoint: {ENDPOINT}")
    print("Request payload:")
    print(json.dumps(payload, indent=2))

    try:
        resp = requests.post(ENDPOINT, json=payload, timeout=180)
        print("\nHTTP Status:", resp.status_code)

        try:
            data = resp.json()
            print("\nResponse JSON:")
            print(json.dumps(data, indent=4))
        except json.JSONDecodeError:
            print("\nResponse is not valid JSON:")
            print(resp.text)

    except Exception as e:
        print("Error calling API:", str(e))


if __name__ == "__main__":
    print("Testing /api/v1/summary_agent/attachment_summary_mcp ...")
    run_test()


